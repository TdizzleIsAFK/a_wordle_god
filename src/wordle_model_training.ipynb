{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Wordle Model Training Notebook\n",
    "\n",
    "This notebook demonstrates how to train your ML model on Google Colab using a powerful GPU (like an A100) and how to save the trained model to Google Drive. \n",
    "\n",
    "You can later deploy this trained model in your web application. Modify the cells below to suit your specific training code and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mount-drive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive to save model checkpoints and data\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-dependencies",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install any additional dependencies if needed (uncomment the following lines):\n",
    "# !pip install torch torchvision torchaudio\n",
    "# !pip install fastapi uvicorn\n",
    "\n",
    "# Note: PyTorch is usually pre-installed in Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import-libraries",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda import amp\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import time\n",
    "\n",
    "print('Using device:', torch.device('cuda' if torch.cuda.is_available() else 'cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeuristicScoringModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=1024, num_hidden_layers=3, dropout=0.3):\n",
    "        super(HeuristicScoringModel, self).__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(input_size, hidden_size))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Dropout(dropout))\n",
    "        for _ in range(num_hidden_layers - 1):\n",
    "            layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        layers.append(nn.Linear(hidden_size, 1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "print('HeuristicScoringModel defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-dataset-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDataset(Dataset):\n",
    "    \"\"\"A simple dataset for demonstration purposes.\"\"\"\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "def train_model(model, dataloader, criterion, optimizer, device, scaler, num_epochs=5, scheduler=None):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with amp.autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss += loss.item() * inputs.size(0)\n",
    "        epoch_loss /= len(dataloader.dataset)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "\n",
    "def evaluate_model(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            with amp.autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "    total_loss /= len(dataloader.dataset)\n",
    "    print(f\"Evaluation Loss: {total_loss:.4f}\")\n",
    "    return total_loss\n",
    "\n",
    "print('Dataset and training functions defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepare-dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demonstration, create a dummy dataset\n",
    "input_size = 100  # Update this if using a different input dimension\n",
    "num_samples = 1000\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Create random data and labels\n",
    "train_data = [torch.randn(input_size) for _ in range(num_samples)]\n",
    "train_labels = [torch.randn(1) for _ in range(num_samples)]\n",
    "\n",
    "# Split into training and validation sets\n",
    "split = int(0.8 * num_samples)\n",
    "train_dataset = ExampleDataset(train_data[:split], train_labels[:split])\n",
    "val_dataset = ExampleDataset(train_data[split:], train_labels[split:])\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}, Validation samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = HeuristicScoringModel(input_size).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scaler = amp.GradScaler()\n",
    "\n",
    "# Optional: Define a learning rate scheduler\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "scheduler = None\n",
    "\n",
    "num_epochs = 5  # Increase the number of epochs as needed\n",
    "start_time = time.time()\n",
    "train_model(model, train_loader, criterion, optimizer, device, scaler, num_epochs=num_epochs, scheduler=scheduler)\n",
    "print(f\"Training completed in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Evaluate on validation set\n",
    "evaluate_model(model, val_loader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to Google Drive\n",
    "model_save_path = '/content/drive/MyDrive/wordle_model.pth'\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f'Model saved to {model_save_path}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Wordle_Model_Training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
